#!/usr/bin/env python3
"""
ğŸ§  PrisMind All-in-One Intelligence Platform
==========================================

Single-file Streamlit app with complete automation:
âœ… Dashboard frontend
âœ… Collection backend  
âœ… AI analysis
âœ… Health monitoring

Deploy to Streamlit Cloud for FREE automation!
"""

import streamlit as st
import pandas as pd
import asyncio
import os
import sys
import json
import time
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import warnings
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Setup paths
sys.path.insert(0, str(Path(__file__).parent))

# Page configuration
st.set_page_config(
    page_title="ğŸ§  PrisMind - Intelligence Platform",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main { padding-top: 1rem; }
    .stButton button { width: 100%; }
    .metric-container { 
        background: #f0f2f6; 
        padding: 1rem; 
        border-radius: 0.5rem; 
        margin: 0.5rem 0;
    }
    .success-message { color: #28a745; }
    .error-message { color: #dc3545; }
    .info-message { color: #17a2b8; }
</style>
""", unsafe_allow_html=True)

# Initialize session state
def init_session_state():
    if 'automation_enabled' not in st.session_state:
        st.session_state.automation_enabled = False
    if 'last_collection' not in st.session_state:
        st.session_state.last_collection = None
    if 'collection_stats' not in st.session_state:
        st.session_state.collection_stats = {"twitter": 0, "reddit": 0, "threads": 0}
    if 'background_collector' not in st.session_state:
        st.session_state.background_collector = None
    if 'background_running' not in st.session_state:
        st.session_state.background_running = False

init_session_state()

# Simple database managers for cloud deployment
class SimpleSupabaseManager:
    """Simple Supabase manager for cloud deployment"""
    def __init__(self, client):
        self.client = client
        self.table_name = 'posts'
    
    def get_all_posts(self, include_deleted=False):
        try:
            # Try to get all posts first, then filter in Python if needed
            response = self.client.table(self.table_name).select('*').execute()
            df = pd.DataFrame(response.data)
            
            # If we need to filter deleted posts, check if the column exists
            if not include_deleted and 'deleted' in df.columns:
                df = df[df['deleted'] == False]
            elif not include_deleted and 'deleted' not in df.columns:
                # If no deleted column exists, return all posts (assume none are deleted)
                pass
            
            # Since we're not using id as post_id anymore, we need to handle this differently
            # For now, we'll use the id as post_id for the app's internal use
            if not df.empty and 'id' in df.columns:
                df = df.rename(columns={'id': 'post_id'})
                
            return df
        except Exception as e:
            st.error(f"Error fetching posts: {e}")
            return pd.DataFrame()
    
    def get_posts(self, limit=100):
        try:
            response = self.client.table(self.table_name).select('*').limit(limit).execute()
            df = pd.DataFrame(response.data)
            
            # Filter deleted posts if the column exists
            if 'deleted' in df.columns:
                df = df[df['deleted'] == False]
            
            # Map 'id' column to 'post_id' for consistency with the rest of the app
            if not df.empty and 'id' in df.columns:
                df = df.rename(columns={'id': 'post_id'})
                
            return df.to_dict('records')
        except Exception as e:
            st.error(f"Error fetching posts: {e}")
            return []
    
    def add_post(self, post_data):
        try:
            # First, check if this post already exists
            post_id = post_data.get('post_id', '')
            url = post_data.get('url', '')
            
            if post_id:
                # Check by post_id first
                try:
                    existing = self.client.table(self.table_name).select('id').eq('id', post_id).execute()
                    if existing.data:
                        print(f"âš ï¸ Post {post_id} already exists, skipping...")
                        return True  # Return True since it's already there
                except:
                    pass
            
            if url:
                # Also check by URL as backup
                try:
                    existing = self.client.table(self.table_name).select('id').eq('url', url).execute()
                    if existing.data:
                        print(f"âš ï¸ Post with URL {url} already exists, skipping...")
                        return True
                except:
                    pass
            
            # Generate a unique ID
            import hashlib
            import time
            
            # Create a unique identifier
            unique_string = f"{post_id}_{url}_{post_data.get('content', '')[:100]}"
            # Use SHA256 hash and take first 8 characters as hex, convert to int
            hash_object = hashlib.sha256(unique_string.encode())
            hash_hex = hash_object.hexdigest()[:8]
            db_id = int(hash_hex, 16) % 2147483647  # Ensure it fits in INTEGER range
            
            # Add timestamp to make it more unique
            timestamp = int(time.time() * 1000) % 1000000  # Last 6 digits of timestamp
            db_id = (db_id + timestamp) % 2147483647
            
            data = {'id': db_id}
            
            # Add the rest of the data
            data.update({
                'platform': post_data.get('platform'),
                'title': post_data.get('title'),
                'content': post_data.get('content'),
                'url': post_data.get('url'),
                'author': post_data.get('author'),
                'value_score': post_data.get('value_score', 0),
                'category': post_data.get('category'),
                'summary': post_data.get('ai_analysis'),  # Map ai_analysis to summary
                'smart_tags': post_data.get('smart_tags', '[]'),
                'ai_summary': post_data.get('ai_analysis')  # Also store in ai_summary field
            })
            
            # Remove None values
            data = {k: v for k, v in data.items() if v is not None}
            
            # Insert into Supabase
            response = self.client.table(self.table_name).insert(data).execute()
            return True
        except Exception as e:
            st.error(f"Error adding post to Supabase: {e}")
            return False

class SQLiteDatabaseManager:
    """Local SQLite database manager"""
    def __init__(self):
        self.db_path = "prismind.db"
        self.init_database()
    
    def init_database(self):
        """Initialize the database with required tables"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Create posts table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS posts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                post_id TEXT UNIQUE,
                platform TEXT,
                title TEXT,
                content TEXT,
                url TEXT,
                author TEXT,
                score REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                ai_analysis TEXT,
                category TEXT,
                value_score REAL,
                deleted BOOLEAN DEFAULT FALSE
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def get_all_posts(self, include_deleted=False):
        try:
            conn = sqlite3.connect(self.db_path)
            if include_deleted:
                query = "SELECT * FROM posts ORDER BY created_at DESC"
            else:
                query = "SELECT * FROM posts WHERE deleted = FALSE ORDER BY created_at DESC"
            
            df = pd.read_sql_query(query, conn)
            conn.close()
            return df
        except Exception as e:
            st.error(f"Error fetching posts: {e}")
            return pd.DataFrame()
    
    def get_posts(self, limit=100):
        try:
            conn = sqlite3.connect(self.db_path)
            query = f"SELECT * FROM posts WHERE deleted = FALSE ORDER BY created_at DESC LIMIT {limit}"
            df = pd.read_sql_query(query, conn)
            conn.close()
            return df.to_dict('records')
        except Exception as e:
            st.error(f"Error fetching posts: {e}")
            return []
    
    def add_post(self, post_data):
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO posts 
                (post_id, platform, title, content, url, author, score, ai_analysis, category, value_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                post_data.get('post_id'),
                post_data.get('platform'),
                post_data.get('title'),
                post_data.get('content'),
                post_data.get('url'),
                post_data.get('author'),
                post_data.get('score', 0),
                post_data.get('ai_analysis'),
                post_data.get('category'),
                post_data.get('value_score', 0)
            ))
            
            conn.commit()
            conn.close()
        except Exception as e:
            st.error(f"Error adding post: {e}")

class InMemoryDatabaseManager:
    """Simple in-memory storage for demo purposes"""
    def __init__(self):
        self.posts = []
    
    def get_all_posts(self, include_deleted=False):
        if include_deleted:
            return pd.DataFrame(self.posts)
        else:
            # Filter out deleted posts
            active_posts = [post for post in self.posts if not post.get('deleted', False)]
            return pd.DataFrame(active_posts)
    
    def get_posts(self, limit=100):
        return self.posts[:limit]
    
    def add_post(self, post_data):
        self.posts.append(post_data)

# Database manager wrapper
@st.cache_resource
def get_database_manager():
    """Get cached database manager"""
    try:
        # Try Supabase first, fallback to SQLite
        if os.getenv('SUPABASE_URL'):
            try:
                from supabase import create_client
                url = os.getenv('SUPABASE_URL')
                key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
                if url and key:
                    # Test the connection first
                    import requests
                    try:
                        # Test with a more specific endpoint
                        test_url = f"{url}/rest/v1/"
                        response = requests.get(test_url, headers={"apikey": key}, timeout=10)
                        if response.status_code in [200, 401]:  # 401 means auth works but no table access
                            client = create_client(url, key)
                            return SimpleSupabaseManager(client)
                        else:
                            st.warning("âš ï¸ Supabase project not accessible, using local database")
                            return SQLiteDatabaseManager()
                    except Exception as e:
                        st.warning(f"âš ï¸ Supabase connection failed: {e}, using local database")
                        return SQLiteDatabaseManager()
            except ImportError:
                st.error("âŒ Supabase library not available. Install with: pip install supabase")
                return SQLiteDatabaseManager()
        else:
            # Use local SQLite database
            return SQLiteDatabaseManager()
    except Exception as e:
        st.error(f"âŒ Database connection failed: {e}")
        return SQLiteDatabaseManager()

# Collection functions
async def run_twitter_collection():
    """Run Twitter bookmark collection"""
    try:
        from collect_multi_platform import collect_twitter_bookmarks
        db_manager = get_database_manager()
        if db_manager is None:
            return 0
        
        # Get existing posts to avoid duplicates
        if hasattr(db_manager, 'get_all_posts'):
            existing_posts = db_manager.get_all_posts(include_deleted=False)
            if not existing_posts.empty and 'post_id' in existing_posts.columns:
                existing_ids = set(existing_posts['post_id'].tolist())
            else:
                existing_ids = set()
        else:
            existing_ids = set()
        
        count = await collect_twitter_bookmarks(db_manager, existing_ids)
        return count
    except Exception as e:
        st.error(f"Twitter collection error: {e}")
        return 0

def run_reddit_collection():
    """Run Reddit saved posts collection"""
    try:
        from collect_multi_platform import collect_reddit_bookmarks
        db_manager = get_database_manager()
        if db_manager is None:
            return 0
        
        # Get existing posts to avoid duplicates  
        if hasattr(db_manager, 'get_all_posts'):
            existing_posts = db_manager.get_all_posts(include_deleted=False)
            if not existing_posts.empty and 'post_id' in existing_posts.columns:
                existing_ids = set(existing_posts['post_id'].tolist())
            else:
                existing_ids = set()
        else:
            existing_ids = set()
        
        count = collect_reddit_bookmarks(db_manager, existing_ids)
        return count
    except Exception as e:
        st.error(f"Reddit collection error: {e}")
        return 0

async def run_threads_collection():
    """Run Threads saved posts collection"""
    try:
        from collect_multi_platform import collect_threads_bookmarks
        db_manager = get_database_manager()
        if db_manager is None:
            return 0
        
        # Get existing posts to avoid duplicates
        if hasattr(db_manager, 'get_all_posts'):
            existing_posts = db_manager.get_all_posts(include_deleted=False)
            if not existing_posts.empty and 'post_id' in existing_posts.columns:
                existing_ids = set(existing_posts['post_id'].tolist())
            else:
                existing_ids = set()
        else:
            existing_ids = set()
        
        count = await collect_threads_bookmarks(db_manager, existing_ids)
        return count
    except Exception as e:
        st.error(f"Threads collection error: {e}")
        return 0

# Sidebar automation controls
with st.sidebar:
    st.title("ğŸ¤– Automation Hub")
    
    # System status
    st.subheader("ğŸ“Š System Status")
    
    # API Keys status
    api_status = {
        "ğŸ”‘ Supabase": bool(os.getenv('SUPABASE_URL')) and bool(os.getenv('SUPABASE_SERVICE_ROLE_KEY')),
        "ğŸ¤– Mistral AI": bool(os.getenv('MISTRAL_API_KEY')),
        "ğŸ§  Gemini AI": bool(os.getenv('GEMINI_API_KEY')),
        "ğŸ¤– Reddit API": bool(os.getenv('REDDIT_CLIENT_ID')),
        "ğŸ¦ Twitter": bool(os.getenv('TWITTER_USERNAME')),
        "ğŸ§µ Threads": bool(os.getenv('THREADS_USERNAME'))
    }
    
    for service, status in api_status.items():
        if status:
            st.success(f"âœ… {service}")
        else:
            st.error(f"âŒ {service}")
    
    st.divider()
    
    # Collection controls
    st.subheader("ğŸš€ Manual Collection")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ¦ Twitter", help="Collect Twitter bookmarks", type="secondary"):
            with st.spinner("ğŸ”„ Collecting Twitter..."):
                count = asyncio.run(run_twitter_collection())
                if count > 0:
                    st.success(f"âœ… Collected {count} Twitter posts!")
                    st.session_state.collection_stats["twitter"] += count
                    st.session_state.last_collection = datetime.now().strftime("%H:%M")
                else:
                    st.info("ğŸ“­ No new Twitter posts found")
    
    with col2:
        if st.button("ğŸ¤– Reddit", help="Collect Reddit saved posts", type="secondary"):
            with st.spinner("ğŸ”„ Collecting Reddit..."):
                count = run_reddit_collection()
                if count > 0:
                    st.success(f"âœ… Collected {count} Reddit posts!")
                    st.session_state.collection_stats["reddit"] += count
                    st.session_state.last_collection = datetime.now().strftime("%H:%M")
                else:
                    st.info("ğŸ“­ No new Reddit posts found")
    
    if st.button("ğŸ§µ Threads", help="Collect Threads saved posts", type="secondary"):
        with st.spinner("ğŸ”„ Collecting Threads..."):
            count = asyncio.run(run_threads_collection())
            if count > 0:
                st.success(f"âœ… Collected {count} Threads posts!")
                st.session_state.collection_stats["threads"] += count
                st.session_state.last_collection = datetime.now().strftime("%H:%M")
            else:
                st.info("ğŸ“­ No new Threads posts found")
    
    if st.button("ğŸš€ Collect All", help="Collect from all platforms", type="primary"):
        with st.spinner("ğŸ”„ Collecting from all platforms..."):
            twitter_count = asyncio.run(run_twitter_collection())
            reddit_count = run_reddit_collection()
            threads_count = asyncio.run(run_threads_collection())
            
            total = twitter_count + reddit_count + threads_count
            if total > 0:
                st.success(f"âœ… Collected {total} total posts!")
                st.session_state.collection_stats["twitter"] += twitter_count
                st.session_state.collection_stats["reddit"] += reddit_count
                st.session_state.collection_stats["threads"] += threads_count
                st.session_state.last_collection = datetime.now().strftime("%H:%M")
            else:
                st.info("ğŸ“­ No new posts found on any platform")
    
    st.divider()
    
    # Background collection controls
    st.subheader("ğŸ”„ Background Collection")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if not st.session_state.background_running:
            if st.button("ğŸš€ Start Background Collection", type="primary"):
                try:
                    from background_collector import start_background_collection
                    st.session_state.background_collector = start_background_collection()
                    st.session_state.background_running = True
                    st.success("âœ… Background collection started!")
                    st.info("ğŸ’¡ Collection will run automatically every hour")
                except Exception as e:
                    st.error(f"âŒ Failed to start background collection: {e}")
        else:
            st.success("ğŸ”„ Background collection is running")
    
    with col2:
        if st.session_state.background_running:
            if st.button("ğŸ›‘ Stop Background Collection"):
                if st.session_state.background_collector:
                    st.session_state.background_collector.stop()
                st.session_state.background_running = False
                st.session_state.background_collector = None
                st.success("âœ… Background collection stopped!")
    
    # Background collection status
    if st.session_state.background_running:
        st.info("""
        ğŸ”„ **Background Collection Active**
        
        - **Collection interval**: Every 60 minutes (configurable)
        - **Max posts per run**: 100 (configurable)
        - **Platforms**: Twitter (50 posts), Reddit (25 posts), Threads (disabled)
        - **Duplicate detection**: Automatic
        - **Error handling**: Automatic retry on failure
        
        ğŸ’¡ **Configuration**: Set environment variables:
        - `COLLECTION_INTERVAL_MINUTES`: Collection frequency
        - `MAX_POSTS_PER_RUN`: Max posts per collection cycle
        - `TWITTER_LIMIT`, `REDDIT_LIMIT`: Platform-specific limits
        """)
    
    st.divider()
    
    # Scraping statistics
    st.subheader("ğŸ“ˆ Scraping Statistics")
    
    try:
        from scrape_state_manager import state_manager
        stats = state_manager.get_scraping_stats()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Total Posts Tracked", stats['total_posts'])
            for platform, count in stats['posts_by_platform'].items():
                st.metric(f"{platform.title()} Posts", count)
        
        with col2:
            for platform_stat in stats['platform_stats']:
                if platform_stat['last_scraped_at']:
                    last_scraped = platform_stat['last_scraped_at'][:19]  # Remove microseconds
                    st.metric(
                        f"{platform_stat['platform'].title()} Last Scrape", 
                        last_scraped,
                        delta=f"{platform_stat['total_posts_scraped']} posts"
                    )
        
        # Reset options
        st.subheader("ğŸ”„ Reset Options")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("Reset Twitter State"):
                state_manager.reset_platform_state('twitter')
                st.success("âœ… Twitter scraping state reset!")
                st.rerun()
        
        with col2:
            if st.button("Reset Reddit State"):
                state_manager.reset_platform_state('reddit')
                st.success("âœ… Reddit scraping state reset!")
                st.rerun()
        
        with col3:
            if st.button("Reset All States"):
                state_manager.reset_platform_state('twitter')
                state_manager.reset_platform_state('reddit')
                st.success("âœ… All scraping states reset!")
                st.rerun()
                
    except Exception as e:
        st.error(f"âŒ Could not load scraping stats: {e}")
    
    st.divider()
    
    # Collection statistics
    st.subheader("ğŸ“ˆ Session Stats")
    if st.session_state.last_collection:
        st.metric("Last Collection", st.session_state.last_collection)
    
    stats = st.session_state.collection_stats
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Twitter", stats["twitter"])
    with col2:
        st.metric("Reddit", stats["reddit"])
    with col3:
        st.metric("Threads", stats["threads"])

# Main content area
st.title("ğŸ§  PrisMind - Intelligent Bookmark Platform")
st.markdown("*Transform your social media bookmarks into structured intelligence*")

# Create tabs for different views
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Dashboard", "ğŸ¯ Browse Posts", "âš™ï¸ Settings"])

with tab1:
    st.header("ğŸ“Š Intelligence Dashboard")
    
    # Database stats
    db_manager = get_database_manager()
    if db_manager:
        try:
            # Get posts data
            if hasattr(db_manager, 'get_all_posts'):
                posts_df = db_manager.get_all_posts()
            elif hasattr(db_manager, 'get_posts'):
                posts_data = db_manager.get_posts(limit=1000)
                posts_df = pd.DataFrame(posts_data)
            else:
                posts_df = pd.DataFrame()
            
            if not posts_df.empty:
                # Overview metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        label="ğŸ“š Total Posts",
                        value=len(posts_df)
                    )
                
                with col2:
                    analyzed = len(posts_df.dropna(subset=['category'])) if 'category' in posts_df.columns else 0
                    st.metric(
                        label="ğŸ¤– AI Analyzed", 
                        value=analyzed,
                        delta=f"{analyzed/len(posts_df)*100:.1f}%" if len(posts_df) > 0 else "0%"
                    )
                
                with col3:
                    platforms = posts_df['platform'].nunique() if 'platform' in posts_df.columns else 0
                    st.metric(
                        label="ğŸŒ Platforms",
                        value=platforms
                    )
                
                with col4:
                    avg_score = posts_df['value_score'].mean() if 'value_score' in posts_df.columns else 0
                    st.metric(
                        label="â­ Avg Score",
                        value=f"{avg_score:.1f}/10" if avg_score > 0 else "N/A"
                    )
                
                # Platform breakdown
                if 'platform' in posts_df.columns:
                    st.subheader("ğŸ“ˆ Platform Distribution")
                    platform_counts = posts_df['platform'].value_counts()
                    
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.bar_chart(platform_counts)
                    with col2:
                        for platform, count in platform_counts.items():
                            st.metric(f"{platform.title()}", count)
                
                # Recent activity
                if 'created_timestamp' in posts_df.columns:
                    st.subheader("ğŸ“… Recent Activity")
                    posts_df['created_timestamp'] = pd.to_datetime(posts_df['created_timestamp'], errors='coerce')
                    recent_posts = posts_df.nlargest(10, 'created_timestamp')
                    
                    for _, post in recent_posts.head(5).iterrows():
                        platform_emoji = {"twitter": "ğŸ¦", "reddit": "ğŸ¤–", "threads": "ğŸ§µ"}.get(post.get('platform', ''), "ğŸ“")
                        st.write(f"{platform_emoji} **{post.get('author', 'Unknown')}**: {post.get('content', 'No content')[:100]}...")
                
            else:
                st.info("ğŸ“­ No posts in database yet. Use the collection buttons in the sidebar to get started!")
                st.markdown("""
                **Getting Started:**
                1. Configure your API keys in the Settings tab
                2. Use the sidebar buttons to collect bookmarks
                3. Watch your intelligence dashboard grow!
                """)
        
        except Exception as e:
            st.error(f"âŒ Could not load dashboard data: {e}")
    else:
        st.error("âŒ Database not available. Please check your configuration.")

with tab2:
    st.header("ğŸ¯ Browse Your Bookmarks")
    
    # Initialize session state for pagination and filters
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 0
    if 'posts_per_page' not in st.session_state:
        st.session_state.posts_per_page = 10
    if 'search_query' not in st.session_state:
        st.session_state.search_query = ""
    
    db_manager = get_database_manager()
    if db_manager:
        try:
            # Cache posts data to avoid reloading
            @st.cache_data(ttl=300)  # Cache for 5 minutes
            def load_posts_data():
                if hasattr(db_manager, 'get_all_posts'):
                    return db_manager.get_all_posts()
                elif hasattr(db_manager, 'get_posts'):
                    posts_data = db_manager.get_posts(limit=1000)  # Increased limit
                    return pd.DataFrame(posts_data)
                else:
                    return pd.DataFrame()
            
            posts_df = load_posts_data()
            
            # Ensure posts_df is a valid DataFrame
            if posts_df is None:
                posts_df = pd.DataFrame()
            
            if not posts_df.empty and len(posts_df) > 0:
                # Search and filters section
                st.subheader("ğŸ” Search & Filters")
                
                # Search bar
                search_query = st.text_input(
                    "ğŸ” Search posts...",
                    value=st.session_state.search_query,
                    placeholder="Search by content, author, or title..."
                )
                st.session_state.search_query = search_query
                
                # Advanced filters
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    platform_filter = st.selectbox(
                        "ğŸŒ Platform", 
                        ['All'] + list(posts_df['platform'].unique()) if 'platform' in posts_df.columns else ['All']
                    )
                
                with col2:
                    category_filter = st.selectbox(
                        "ğŸ“‚ Category",
                        ['All'] + list(posts_df['category'].dropna().unique()) if 'category' in posts_df.columns else ['All']
                    )
                
                with col3:
                    sort_by = st.selectbox(
                        "ğŸ“Š Sort by",
                        ["Recent", "Value Score", "Author", "Platform"]
                    )
                
                with col4:
                    st.session_state.posts_per_page = st.selectbox(
                        "ğŸ“„ Posts per page",
                        [5, 10, 20, 50],
                        index=1
                    )
                
                # Apply filters
                filtered_df = posts_df.copy()
                
                # Search filter
                if search_query:
                    try:
                        search_mask = (
                            filtered_df['content'].str.contains(search_query, case=False, na=False) |
                            filtered_df['author'].str.contains(search_query, case=False, na=False) |
                            filtered_df['title'].str.contains(search_query, case=False, na=False)
                        )
                        filtered_df = filtered_df[search_mask]
                    except Exception as e:
                        st.warning(f"âš ï¸ Search error: {e}")
                        # Fallback to simple search
                        search_mask = filtered_df.apply(
                            lambda row: search_query.lower() in str(row).lower(), axis=1
                        )
                        filtered_df = filtered_df[search_mask]
                
                # Platform filter
                if platform_filter != 'All' and 'platform' in filtered_df.columns:
                    filtered_df = filtered_df[filtered_df['platform'] == platform_filter]
                
                # Category filter
                if category_filter != 'All' and 'category' in filtered_df.columns:
                    filtered_df = filtered_df[filtered_df['category'] == category_filter]
                
                # Sort
                if sort_by == "Recent" and 'created_timestamp' in filtered_df.columns:
                    filtered_df = filtered_df.sort_values('created_timestamp', ascending=False)
                elif sort_by == "Value Score" and 'value_score' in filtered_df.columns:
                    filtered_df = filtered_df.sort_values('value_score', ascending=False, na_last=True)
                elif sort_by == "Author" and 'author' in filtered_df.columns:
                    filtered_df = filtered_df.sort_values('author')
                elif sort_by == "Platform" and 'platform' in filtered_df.columns:
                    filtered_df = filtered_df.sort_values('platform')
                
                # Pagination
                total_posts = len(filtered_df)
                total_pages = (total_posts + st.session_state.posts_per_page - 1) // st.session_state.posts_per_page
                
                # Pagination controls
                col1, col2, col3 = st.columns([1, 2, 1])
                
                with col1:
                    if st.button("â¬…ï¸ Previous") and st.session_state.current_page > 0:
                        st.session_state.current_page -= 1
                        st.rerun()
                
                with col2:
                    st.write(f"ğŸ“„ Page {st.session_state.current_page + 1} of {total_pages} ({total_posts} total posts)")
                
                with col3:
                    if st.button("â¡ï¸ Next") and st.session_state.current_page < total_pages - 1:
                        st.session_state.current_page += 1
                        st.rerun()
                
                # Reset pagination when filters change
                if st.button("ğŸ”„ Reset to Page 1"):
                    st.session_state.current_page = 0
                    st.rerun()
                
                # Calculate current page data
                start_idx = st.session_state.current_page * st.session_state.posts_per_page
                end_idx = min(start_idx + st.session_state.posts_per_page, total_posts)
                
                try:
                    current_posts = filtered_df.iloc[start_idx:end_idx]
                except Exception as e:
                    st.error(f"âŒ Pagination error: {e}")
                    current_posts = filtered_df.head(st.session_state.posts_per_page)
                
                # Display posts with better layout
                st.subheader(f"ğŸ“ Posts ({start_idx + 1}-{end_idx} of {total_posts})")
                
                # Quick overview of current results
                if total_posts > 0:
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        platforms_in_view = filtered_df['platform'].nunique() if 'platform' in filtered_df.columns else 0
                        st.metric("ğŸŒ Platforms", platforms_in_view)
                    
                    with col2:
                        categories_in_view = filtered_df['category'].nunique() if 'category' in filtered_df.columns else 0
                        st.metric("ğŸ“‚ Categories", categories_in_view)
                    
                    with col3:
                        avg_score = filtered_df['value_score'].mean() if 'value_score' in filtered_df.columns else 0
                        st.metric("â­ Avg Score", f"{avg_score:.1f}/10" if avg_score > 0 else "N/A")
                    
                    with col4:
                        try:
                            if 'category' in filtered_df.columns and len(filtered_df) > 0:
                                category_mode = filtered_df['category'].mode()
                                if len(category_mode) > 0:
                                    top_category = category_mode.iloc[0]
                                    display_category = top_category[:15] + "..." if len(str(top_category)) > 15 else top_category
                                else:
                                    display_category = "N/A"
                            else:
                                display_category = "N/A"
                            st.metric("ğŸ† Top Category", display_category)
                        except Exception as e:
                            st.metric("ğŸ† Top Category", "N/A")
                    
                    st.divider()
                
                for idx, post in current_posts.iterrows():
                    try:
                        # Safely get post data with defaults
                        platform = str(post.get('platform', '')) if post.get('platform') is not None else ''
                        platform_emoji = {"twitter": "ğŸ¦", "reddit": "ğŸ¤–", "threads": "ğŸ§µ"}.get(platform, "ğŸ“")
                        
                        score = post.get('value_score')
                        if score is not None and score != 'N/A':
                            try:
                                score_float = float(score)
                                score_display = f"â­{score_float:.1f}/10"
                            except (ValueError, TypeError):
                                score_display = "â­N/A"
                        else:
                            score_display = "â­N/A"
                        
                        # Safely get text fields
                        author = str(post.get('author', 'Unknown')) if post.get('author') is not None else 'Unknown'
                        title = str(post.get('title', 'No title')) if post.get('title') is not None else 'No title'
                        content = str(post.get('content', 'No content')) if post.get('content') is not None else 'No content'
                        
                        # Create expander title safely
                        title_preview = title[:40] + "..." if len(title) > 40 else title
                        expander_title = f"{platform_emoji} {author} - {title_preview} {score_display}"
                        
                        # Create expandable post card
                        with st.expander(expander_title, expanded=False):
                            col1, col2 = st.columns([3, 1])
                            
                            with col1:
                                st.markdown(f"**{title}**")
                                st.markdown(f"*by {author} on {platform}*")
                                
                                # Content with better formatting
                                if content and len(content) > 500:
                                    st.markdown(f"{content[:500]}...")
                                    with st.expander("Show full content"):
                                        st.markdown(content)
                                elif content:
                                    st.markdown(content)
                                else:
                                    st.markdown("*No content available*")
                                
                                # Metadata
                                col_meta1, col_meta2, col_meta3 = st.columns(3)
                                with col_meta1:
                                    category = str(post.get('category', 'Uncategorized')) if post.get('category') is not None else 'Uncategorized'
                                    st.markdown(f"**Category:** {category}")
                                with col_meta2:
                                    st.markdown(f"**Score:** {score_display}")
                                with col_meta3:
                                    try:
                                        created_timestamp = post.get('created_timestamp')
                                        if created_timestamp and created_timestamp is not None:
                                            created_date = pd.to_datetime(created_timestamp).strftime('%Y-%m-%d')
                                            st.markdown(f"**Date:** {created_date}")
                                        else:
                                            st.markdown("**Date:** Unknown")
                                    except Exception:
                                        st.markdown("**Date:** Unknown")
                            
                            with col2:
                                # URL link
                                url = post.get('url')
                                if url and url is not None:
                                    st.markdown(f"[ğŸ”— View Original]({url})")
                                
                                # AI analysis summary if available
                                try:
                                    ai_summary = post.get('ai_summary')
                                    summary = post.get('summary')
                                    
                                    if ai_summary and ai_summary is not None:
                                        summary_text = str(ai_summary)
                                    elif summary and summary is not None:
                                        summary_text = str(summary)
                                    else:
                                        summary_text = None
                                    
                                    if summary_text and len(summary_text) > 100:
                                        with st.expander("ğŸ¤– AI Summary"):
                                            display_summary = summary_text[:200] + "..." if len(summary_text) > 200 else summary_text
                                            st.markdown(display_summary)
                                except Exception:
                                    pass  # Silently skip if there's an error with summary
                    except Exception as e:
                        st.error(f"âŒ Error displaying post {idx}: {e}")
                        continue
                
                # Quick stats
                st.subheader("ğŸ“Š Quick Stats")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Total Posts", total_posts)
                with col2:
                    try:
                        if 'category' in filtered_df.columns:
                            analyzed = len(filtered_df.dropna(subset=['category']))
                        else:
                            analyzed = 0
                        percentage = f"{analyzed/total_posts*100:.1f}%" if total_posts > 0 else "0%"
                        st.metric("AI Analyzed", analyzed, percentage)
                    except Exception:
                        st.metric("AI Analyzed", 0, "0%")
                with col3:
                    try:
                        if 'value_score' in filtered_df.columns:
                            avg_score = filtered_df['value_score'].mean()
                            if pd.isna(avg_score) or avg_score is None:
                                avg_score = 0
                        else:
                            avg_score = 0
                        st.metric("Avg Score", f"{avg_score:.1f}/10" if avg_score > 0 else "N/A")
                    except Exception:
                        st.metric("Avg Score", "N/A")
                with col4:
                    try:
                        if 'platform' in filtered_df.columns:
                            platforms = filtered_df['platform'].nunique()
                        else:
                            platforms = 0
                        st.metric("Platforms", platforms)
                    except Exception:
                        st.metric("Platforms", 0)
                
            else:
                st.info("ğŸ“­ No posts found. Start collecting from the sidebar!")
                
                # Helpful tips section
                st.subheader("ğŸ’¡ Tips for Better Browsing")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("""
                    **ğŸ” Search Tips:**
                    - Search by author name
                    - Search by content keywords
                    - Search by post title
                    - Use quotes for exact phrases
                    """)
                
                with col2:
                    st.markdown("""
                    **ğŸ“Š Filter Tips:**
                    - Filter by platform (Twitter, Reddit)
                    - Filter by AI category
                    - Sort by value score to find best content
                    - Use pagination to browse large collections
                    """)
                
                st.markdown("""
                **ğŸš€ Getting Started:**
                1. Use the sidebar collection buttons to gather bookmarks
                2. Wait for AI analysis to complete
                3. Browse your intelligent content here!
                4. Use search and filters to find specific content
                """)
                
        except Exception as e:
            st.error(f"âŒ Could not load posts: {e}")
            st.error("ğŸ’¡ Try refreshing the page or checking your database connection")

with tab3:
    st.header("âš™ï¸ Configuration")
    
    st.subheader("ğŸ”‘ API Configuration")
    st.markdown("""
    Configure your API keys in Streamlit Cloud:
    1. Go to your app settings
    2. Click "Secrets"
    3. Add your API keys in TOML format:
    """)
    
    st.code("""
[secrets]
SUPABASE_URL = "your_supabase_url"
SUPABASE_SERVICE_ROLE_KEY = "your_service_key"
MISTRAL_API_KEY = "your_mistral_key"
GEMINI_API_KEY = "your_gemini_key"
REDDIT_CLIENT_ID = "your_reddit_client_id"
REDDIT_CLIENT_SECRET = "your_reddit_secret"
REDDIT_USERNAME = "your_reddit_username"
REDDIT_PASSWORD = "your_reddit_password"
TWITTER_USERNAME = "your_twitter_username"
THREADS_USERNAME = "your_threads_username"
    """)
    
    st.subheader("ğŸ—„ï¸ Database Connection")
    if st.button("Test Database Connection"):
        db_manager = get_database_manager()
        if db_manager:
            try:
                if hasattr(db_manager, 'get_all_posts'):
                    posts_df = db_manager.get_all_posts()
                    st.success(f"âœ… Database connected! Found {len(posts_df)} posts.")
                elif hasattr(db_manager, 'get_posts'):
                    posts = db_manager.get_posts(limit=1)
                    st.success(f"âœ… Database connected!")
                else:
                    st.success("âœ… Database manager loaded successfully!")
            except Exception as e:
                st.error(f"âŒ Database test failed: {e}")
        else:
            st.error("âŒ Could not initialize database manager")
    
    st.subheader("â„¹ï¸ About")
    st.markdown("""
    **PrisMind All-in-One** - Your complete social media intelligence platform
    
    - ğŸ¤– **Automated collection** from Twitter, Reddit, Threads
    - ğŸ§  **AI-powered analysis** and categorization  
    - ğŸ“Š **Intelligence dashboard** with insights
    - ğŸ”„ **Real-time manual triggers**
    - ğŸ†“ **100% FREE** on Streamlit Cloud
    
    Built with â¤ï¸ by the PrisMind team
    """)

# Footer
st.markdown("---")
st.markdown("ğŸ§  **PrisMind** - Transform your bookmarks into intelligence | ğŸš€ Powered by Streamlit Cloud")
